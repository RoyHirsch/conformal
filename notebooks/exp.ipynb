{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from matplotlib.image import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cached data\n",
    "if not os.path.exists('../data'):\n",
    "    os.system('gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz')\n",
    "    os.system('tar -xf ../data.tar.gz -C ../')\n",
    "    os.system('rm ../data.tar.gz')\n",
    "if not os.path.exists('../data/imagenet/human_readable_labels.json'):\n",
    "    !wget -nv -O ../data/imagenet/human_readable_labels.json -L https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\n",
    "\n",
    "data = np.load('../data/imagenet/imagenet-resnet152.npz')\n",
    "example_paths = os.listdir('../data/imagenet/examples')\n",
    "smx = data['smx']\n",
    "labels = data['labels'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n = 1000 # number of calibration points\n",
    "alpha = 0.1 # 1-alpha is the desired coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "idx = np.array([1] * n + [0] * (smx.shape[0]-n)) > 0\n",
    "np.random.shuffle(idx)\n",
    "cal_smx, val_smx = smx[idx,:], smx[~idx,:]\n",
    "cal_labels, val_labels = labels[idx], labels[~idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.3006938775510204\n"
     ]
    }
   ],
   "source": [
    "qhat = 1 - alpha\n",
    "val_pi = val_smx.argsort(1)[:,::-1]\n",
    "val_srt = np.take_along_axis(val_smx,val_pi,axis=1).cumsum(axis=1)\n",
    "prediction_sets = np.take_along_axis(val_srt <=\n",
    "                                      qhat, val_pi.argsort(axis=1), axis=1)\n",
    "\n",
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),val_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.8936938775510204\n",
      "The sets sizes are: 1.7 (1.05))\n"
     ]
    }
   ],
   "source": [
    "# 1: get conformal scores. n = calib_Y.shape[0]\n",
    "cal_scores = 1-cal_smx[np.arange(n),cal_labels]\n",
    "# 2: get adjusted quantile\n",
    "q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "prediction_sets = val_smx >= (1-qhat) # 3: form prediction sets\n",
    "\n",
    "# Calculate empirical coverage\n",
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),val_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")\n",
    "\n",
    "set_sizes = prediction_sets.sum(1)\n",
    "print(f\"The sets sizes are: {np.round(set_sizes.mean(), 1)} ({np.round(set_sizes.std(), 2)}))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33,  36,   0, 391, 397])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_pi[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6325930953025818, 0.06433039158582687, 0.058940235525369644)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_smx[0,33], cal_smx[0,36], cal_smx[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_pi = cal_smx.argsort(1)[:,::-1]\n",
    "cal_srt = np.take_along_axis(cal_smx, cal_pi, axis=1).cumsum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.9147755102040817\n",
      "The sets sizes are: 243.4 (302.69))\n"
     ]
    }
   ],
   "source": [
    "# Get scores. calib_X.shape[0] == calib_Y.shape[0] == n\n",
    "cal_pi = cal_smx.argsort(1)[:,::-1]\n",
    "cal_srt = np.take_along_axis(cal_smx,cal_pi,axis=1).cumsum(axis=1)\n",
    "cal_scores = np.take_along_axis(cal_srt,cal_pi.argsort(axis=1),axis=1)[range(n),cal_labels]\n",
    "\n",
    "# Get the score quantile\n",
    "qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, interpolation='higher')\n",
    "\n",
    "# Deploy (output=list of length n, each element is tensor of classes)\n",
    "val_pi = val_smx.argsort(1)[:,::-1]\n",
    "val_srt = np.take_along_axis(val_smx,val_pi,axis=1).cumsum(axis=1)\n",
    "prediction_sets = np.take_along_axis(val_srt <= qhat,val_pi.argsort(axis=1),axis=1)\n",
    "\n",
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),val_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")\n",
    "\n",
    "set_sizes = prediction_sets.sum(1)\n",
    "print(f\"The sets sizes are: {np.round(set_sizes.mean(), 1)} ({np.round(set_sizes.std(), 2)}))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet\n",
    "# https://github.com/pytorch/examples/tree/main/imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/royhirsch/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/royhirsch/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1408])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EmbedResnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "\n",
    "        x = self.model.avgpool(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "    def fc(self, x):\n",
    "        return self.model.fc(x)\n",
    "\n",
    "class EmbedRepVGG(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = self.model.stage0(x)\n",
    "        out = self.model.stage1(out)\n",
    "        out = self.model.stage2(out)\n",
    "        out = self.model.stage3(out)\n",
    "        out = self.model.stage4(out)\n",
    "        out = self.model.gap(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out\n",
    "\n",
    "    def fc(self, x):\n",
    "        return self.model.linear(x)\n",
    "\n",
    "# https://github.com/chenyaofo/pytorch-cifar-models\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_repvgg_a2\", pretrained=True)\n",
    "embed_model = EmbedRepVGG(model)\n",
    "embed_model(torch.rand(1,3,224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "_MEAN = [0.5070751592371323, 0.48654887331495095, 0.4409178433670343]\n",
    "_STD = [0.26733428587941854, 0.25643846292120615, 0.2761504713263903]\n",
    "\n",
    "\n",
    "transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                              tt.RandomHorizontalFlip(), \n",
    "                              tt.ToTensor(), \n",
    "                              tt.Normalize(_MEAN,_STD,inplace=True)])\n",
    "transform_test = tt.Compose([tt.ToTensor(), tt.Normalize(_MEAN,_STD)])\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 1\n",
    "trainset = torchvision.datasets.CIFAR100(\"./\",\n",
    "                                         train=True,\n",
    "                                         download=True,\n",
    "                                         transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size, shuffle=True, num_workers=num_workers,pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\"./\",\n",
    "                                        train=False,\n",
    "                                        download=True,\n",
    "                                        transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size,pin_memory=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeds(device, loader):\n",
    "    model = embed_model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_embeds = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[0].to(device)\n",
    "            embeds = embed_model(x)\n",
    "            preds = embed_model.fc(embeds)\n",
    "\n",
    "            embeds = embeds.detach().cpu().numpy()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            all_embeds.append(embeds)\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(batch[1].numpy())\n",
    "\n",
    "    all_embeds = np.concatenate(all_embeds, 0)\n",
    "    all_preds = np.concatenate(all_preds, 0)\n",
    "    all_labels = np.concatenate(all_labels, 0)\n",
    "    return all_embeds, all_preds, all_labels\n",
    "\n",
    "def save_pickle(data, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1408)\n",
      "0.99808\n",
      "(10000, 1408)\n",
      "0.748\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:6')\n",
    "out_dir = '/home/royhirsch/conformal/cifar100_repvgg_a2'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "train_embeds, train_preds, train_labels = get_embeds(device, trainloader)\n",
    "print(train_embeds.shape)\n",
    "print((train_preds.argmax(1) == train_labels).mean())\n",
    "save_pickle({'embeds': train_embeds,\n",
    "             'preds': train_preds,\n",
    "             'labels': train_labels}, os.path.join(out_dir, 'train.pickle'))\n",
    "test_embeds, test_preds, test_labels = get_embeds(device, testloader)\n",
    "print(test_embeds.shape)\n",
    "print((test_preds.argmax(1) == test_labels).mean())\n",
    "save_pickle({'embeds': test_embeds,\n",
    "             'preds': test_preds,\n",
    "             'labels': test_labels}, os.path.join(out_dir, 'test.pickle'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fbnetc_100',\n",
       " 'ghostnet_100',\n",
       " 'lcnet_100',\n",
       " 'mnasnet_100',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobilevitv2_100',\n",
       " 'rexnet_100',\n",
       " 'rexnetr_100',\n",
       " 'semnasnet_100',\n",
       " 'spnasnet_100',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm \n",
    "timm.list_models('*100*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5475.42s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/royhirsch/.kaggle/kaggle.json'\n",
      "403 - Forbidden - You must accept this competition's rules before you'll be able to download files.\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c imagenet-object-localization-challenge\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
