{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 07/23/23 11:00:49 - 0:00:00 - Created main log at /home/royhirsch/conformal/exps/temp/net_launcher_log.log\n",
      "INFO - 07/23/23 11:00:52 - 0:00:04 - Baseline mets: acc=0.867 | qhat: 0.989 | set size: 214.54 (161.799)\n",
      "INFO - 07/23/23 11:00:54 - 0:00:06 - NN(\n",
      "                                       (layers): Linear(in_features=2048, out_features=1, bias=True)\n",
      "                                     )\n",
      "INFO - 07/23/23 11:00:54 - 0:00:06 - Start training for 50 epochs:\n",
      "INFO - 07/23/23 11:00:54 - 0:00:06 - Number of batches in train epoch: 313\n",
      "INFO - 07/23/23 11:00:54 - 0:00:06 - E 1/50 |\n",
      "0it [00:00, ?it/s]\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [0,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m utils\u001b[39m.\u001b[39mseed_everything(config\u001b[39m.\u001b[39mseed)\n\u001b[1;32m      8\u001b[0m utils\u001b[39m.\u001b[39mcreate_logger(config\u001b[39m.\u001b[39mexp_dir, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m history, val_outputs, train_outputs, val_mets, train_mets \u001b[39m=\u001b[39m experiment(config)\n",
      "File \u001b[0;32m~/conformal/experiment.py:121\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    116\u001b[0m criteria \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\n\u001b[1;32m    118\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(criteria,\n\u001b[1;32m    119\u001b[0m                   utils\u001b[39m.\u001b[39mRegressionMetricLogger,\n\u001b[1;32m    120\u001b[0m                   config\u001b[39m=\u001b[39mconfig)\n\u001b[0;32m--> 121\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    122\u001b[0m             train_loader\u001b[39m=\u001b[39;49mtrain_dl,\n\u001b[1;32m    123\u001b[0m             test_loader\u001b[39m=\u001b[39;49mvalid_dl,\n\u001b[1;32m    124\u001b[0m             optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    125\u001b[0m             scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m    126\u001b[0m             valid_loader\u001b[39m=\u001b[39;49mvalid_dl)\n\u001b[1;32m    128\u001b[0m val_predict_out \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(model, valid_dl)\n\u001b[1;32m    129\u001b[0m sets \u001b[39m=\u001b[39m conformal_module\u001b[39m.\u001b[39mget_sets(\n\u001b[1;32m    130\u001b[0m     val_predict_out[\u001b[39m'\u001b[39m\u001b[39mpred_scores\u001b[39m\u001b[39m'\u001b[39m], val_predict_out[\u001b[39m'\u001b[39m\u001b[39mtrue_scores\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    131\u001b[0m     val_predict_out[\u001b[39m'\u001b[39m\u001b[39mcls_logits\u001b[39m\u001b[39m'\u001b[39m], t)\n",
      "File \u001b[0;32m~/conformal/trainer.py:134\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_loader, test_loader, optimizer, scheduler, valid_loader)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    132\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mE \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m |\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch, num_epochs))\n\u001b[0;32m--> 134\u001b[0m     train_mets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(model, train_loader, optimizer)\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_mets(train_mets, epoch, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_history_update(train_mets)\n",
      "File \u001b[0;32m~/conformal/trainer.py:78\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     75\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(model, batch)\n\u001b[1;32m     76\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalc_loss(predictions, batch)\n\u001b[0;32m---> 78\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     79\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     81\u001b[0m met\u001b[39m.\u001b[39mupdate(predictions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_label(batch), batch[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m], batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/conf/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/conf/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils as utils\n",
    "from experiment import get_config, experiment\n",
    "\n",
    "config = get_config()\n",
    "utils.seed_everything(config.seed)\n",
    "utils.create_logger(config.exp_dir, False)\n",
    "history, val_outputs, train_outputs, val_mets, train_mets = experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 50\n",
    "plt.hist(val_outputs['pred_scores'], bins, label='Pred scores', alpha=0.3)\n",
    "plt.hist(val_outputs['true_scores'], bins, label='True scores', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.title('Validation conformal scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 50\n",
    "plt.hist(train_outputs['pred_scores'], bins, label='Pred scores', alpha=0.3)\n",
    "plt.hist(train_outputs['true_scores'], bins, label='True scores', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.title('Train conformal scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 50\n",
    "plt.hist(np.abs(val_outputs['pred_scores'] - val_outputs['true_scores']), bins, label='Validation', alpha=0.3, density=True)\n",
    "plt.hist(np.abs(train_outputs['pred_scores'] - train_outputs['true_scores']), bins, label='Train', alpha=0.3, density=True)\n",
    "plt.legend()\n",
    "plt.title('Error (L1) hist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "plt.plot(history['loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
